{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Regression Assignment Questions"
      ],
      "metadata": {
        "id": "q45B-5E5PFCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is Simple Linear Regression?**\n",
        "Simple Linear Regression is a statistical technique used to model the relationship between one independent variable (X) and one dependent variable (Y). It assumes that the relationship between X and Y can be represented by a straight line and is used to predict Y based on X.\n",
        "\n",
        "---\n",
        "\n",
        "**2. What are the key assumptions of Simple Linear Regression?**\n",
        "The key assumptions of Simple Linear Regression are:\n",
        "\n",
        "1. There is a linear relationship between X and Y.\n",
        "2. The observations are independent.\n",
        "3. The residuals have constant variance (homoscedasticity).\n",
        "4. The residuals are normally distributed.\n",
        "5. There are no significant outliers affecting the model.\n",
        "\n",
        "---\n",
        "\n",
        "**3. What does the coefficient *m* represent in the equation Y = mX + c?**\n",
        "The coefficient *m* represents the slope of the regression line. It indicates the amount by which the dependent variable Y changes for a one-unit change in the independent variable X.\n",
        "\n",
        "---\n",
        "\n",
        "**4. What does the intercept *c* represent in the equation Y = mX + c?**\n",
        "The intercept *c* represents the value of Y when X is equal to zero. It shows the point where the regression line intersects the Y-axis.\n",
        "\n",
        "---\n",
        "\n",
        "**5. How do we calculate the slope *m* in Simple Linear Regression?**\n",
        "The slope *m* is calculated using the formula:\n",
        "m = Covariance(X, Y) / Variance(X).\n",
        "It measures the strength and direction of the linear relationship between X and Y.\n",
        "\n",
        "---\n",
        "\n",
        "**6. What is the purpose of the least squares method in Simple Linear Regression?**\n",
        "The least squares method is used to determine the best-fitting regression line by minimizing the sum of the squared differences between the observed values and the predicted values.\n",
        "\n",
        "---\n",
        "\n",
        "**7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?**\n",
        "R² represents the proportion of the variance in the dependent variable that is explained by the independent variable. A higher R² value indicates a better model fit.\n",
        "\n",
        "---\n",
        "\n",
        "**8. What is Multiple Linear Regression?**\n",
        "Multiple Linear Regression is a statistical technique used to analyze the relationship between one dependent variable and two or more independent variables.\n",
        "\n",
        "---\n",
        "\n",
        "**9. What is the main difference between Simple and Multiple Linear Regression?**\n",
        "Simple Linear Regression uses one independent variable, whereas Multiple Linear Regression uses two or more independent variables to predict the dependent variable.\n",
        "\n",
        "---\n",
        "\n",
        "**10. What are the key assumptions of Multiple Linear Regression?**\n",
        "The key assumptions of Multiple Linear Regression include:\n",
        "\n",
        "1. Linear relationship between variables.\n",
        "2. Independence of errors.\n",
        "3. Homoscedasticity of residuals.\n",
        "4. No multicollinearity among independent variables.\n",
        "5. Normal distribution of residuals.\n",
        "\n",
        "---\n",
        "\n",
        "**11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?**\n",
        "Heteroscedasticity occurs when the variance of residuals is not constant. It can lead to inefficient estimates and unreliable hypothesis testing.\n",
        "\n",
        "---\n",
        "\n",
        "**12. How can you improve a Multiple Linear Regression model with high multicollinearity?**\n",
        "Multicollinearity can be reduced by removing correlated variables, combining variables, using principal component analysis, or applying regularization techniques such as Ridge or Lasso regression.\n",
        "\n",
        "---\n",
        "\n",
        "**13. What are some common techniques for transforming categorical variables for use in regression models?**\n",
        "Common techniques include one-hot encoding, label encoding, and creating dummy variables.\n",
        "\n",
        "---\n",
        "\n",
        "**14. What is the role of interaction terms in Multiple Linear Regression?**\n",
        "Interaction terms capture the combined effect of two or more independent variables on the dependent variable, allowing the relationship to change based on variable interactions.\n",
        "\n",
        "---\n",
        "\n",
        "**15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**\n",
        "In Simple Linear Regression, the intercept represents Y when X equals zero. In Multiple Linear Regression, it represents Y when all independent variables are zero, which may not always be meaningful.\n",
        "\n",
        "---\n",
        "\n",
        "**16. What is the significance of the slope in regression analysis, and how does it affect predictions?**\n",
        "The slope indicates the rate of change of the dependent variable with respect to an independent variable and directly affects the predicted values.\n",
        "\n",
        "---\n",
        "\n",
        "**17. How does the intercept in a regression model provide context for the relationship between variables?**\n",
        "The intercept provides a baseline value of the dependent variable, helping to understand the starting point of the relationship.\n",
        "\n",
        "---\n",
        "\n",
        "**18. What are the limitations of using R² as a sole measure of model performance?**\n",
        "R² does not indicate causality, can increase with additional variables even if they are irrelevant, and does not reflect prediction accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "**19. How would you interpret a large standard error for a regression coefficient?**\n",
        "A large standard error indicates that the coefficient estimate is less precise and may not be statistically significant.\n",
        "\n",
        "---\n",
        "\n",
        "**20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?**\n",
        "Heteroscedasticity can be identified when residuals show a funnel or pattern in plots. It is important to address it to ensure reliable statistical inference.\n",
        "\n",
        "---\n",
        "\n",
        "**21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?**\n",
        "It indicates that additional variables do not significantly improve the model and may be unnecessary.\n",
        "\n",
        "---\n",
        "\n",
        "**22. Why is it important to scale variables in Multiple Linear Regression?**\n",
        "Scaling ensures that variables are on the same scale, improves numerical stability, and is essential for models using regularization.\n",
        "\n",
        "---\n",
        "\n",
        "**23. What is polynomial regression?**\n",
        "Polynomial regression models the relationship between variables by including polynomial terms of the independent variable.\n",
        "\n",
        "---\n",
        "\n",
        "**24. How does polynomial regression differ from linear regression?**\n",
        "Polynomial regression captures non-linear relationships, whereas linear regression assumes a straight-line relationship.\n",
        "\n",
        "---\n",
        "\n",
        "**25. When is polynomial regression used?**\n",
        "Polynomial regression is used when data shows a curved or non-linear trend.\n",
        "\n",
        "---\n",
        "\n",
        "**26. What is the general equation for polynomial regression?**\n",
        "The general equation is:\n",
        "Y = b₀ + b₁X + b₂X² + ... + bₙXⁿ.\n",
        "\n",
        "---\n",
        "\n",
        "**27. Can polynomial regression be applied to multiple variables?**\n",
        "Yes, polynomial regression can be extended to multiple independent variables.\n",
        "\n",
        "---\n",
        "\n",
        "**28. What are the limitations of polynomial regression?**\n",
        "It may overfit the data, be sensitive to outliers, and become difficult to interpret for higher degrees.\n",
        "\n",
        "---\n",
        "\n",
        "**29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?**\n",
        "Methods include cross-validation, adjusted R², mean squared error, and visual inspection of residual plots.\n",
        "\n",
        "---\n",
        "\n",
        "**30. Why is visualization important in polynomial regression?**\n",
        "Visualization helps in understanding non-linear patterns and assessing model fit.\n",
        "\n",
        "---\n",
        "\n",
        "**31. How is polynomial regression implemented in Python?**\n",
        "Polynomial regression is implemented using libraries such as NumPy and scikit-learn by transforming features using polynomial features and applying linear regression.\n",
        "\n"
      ],
      "metadata": {
        "id": "odACjNHZPLZL"
      }
    }
  ]
}